{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "import generator\n",
    "import json\n",
    "from pathlib import Path\n",
    "import sklearn.cluster\n",
    "from sklearn.metrics import f1_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "DB, labels = generator.generate_subspacedata(100, 100, False, [[5, 4, 1, 0.001],\n",
    "                                                              [5, 6, 1, 0.001],\n",
    "                                                              [5, 9, 1, 0.001],\n",
    "                                                              [5, 9, 1, 0.001],\n",
    "                                                              [5, 9, 1, 0.001]])\n",
    "np.savetxt(\"res/sample6.csv\", DB, delimiter=\",\", fmt='%1.8f')\n",
    "\n",
    "# generates the corresponding ground_truth.csv file from the labels matrix\n",
    "with open(\"res/ground_truth.csv\", mode=\"w\") as output_file:\n",
    "    cluster_counter = 1\n",
    "    while np.argwhere(labels == cluster_counter).size > 0:\n",
    "        dimensions = list(set(np.argwhere(labels == cluster_counter)[:,1]))\n",
    "        U = list(set(np.argwhere(labels == cluster_counter)[:,0]))\n",
    "        cluster_counter += 1\n",
    "        output_file.write(str(dimensions) + \"-\" + str(U) + \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration for creating the database: 38ms\n",
      "Duration for calculating the density chunks: 0ms\n",
      "Slice number: 8, size of collision map: 27\n",
      "Slice number: 0, size of collision map: 1\n",
      "Duration for calculating subspaces in slice 0: 0ms\n",
      "Slice number: 1, size of collision map: 4\n",
      "Duration for calculating subspaces in slice 1: 1ms\n",
      "Slice number: 2, size of collision map: 9\n",
      "Duration for calculating subspaces in slice 2: 0ms\n",
      "Slice number: 3, size of collision map: 12\n",
      "Duration for calculating subspaces in slice 3: 0ms\n",
      "Slice number: 4, size of collision map: 23\n",
      "Duration for calculating subspaces in slice 4: 0ms\n",
      "Slice number: 5, size of collision map: 30\n",
      "Duration for calculating subspaces in slice 5: 0ms\n",
      "Slice number: 6, size of collision map: 20\n",
      "Duration for calculating subspaces in slice 6: 0ms\n",
      "Slice number: 7, size of collision map: 11\n",
      "Duration for calculating subspaces in slice 7: 0ms\n",
      "Slice number: 8, size of collision map: 17\n",
      "Duration for calculating subspaces in slice 8: 0ms\n",
      "Slice number: 9, size of collision map: 14\n",
      "Duration for calculating subspaces in slice 9: 0ms\n",
      "Slice number: 10, size of collision map: 13\n",
      "Duration for calculating subspaces in slice 10: 0ms\n",
      "Slice number: 11, size of collision map: 7\n",
      "Duration for calculating subspaces in slice 11: 0ms\n",
      "Slice number: 12, size of collision map: 13\n",
      "Duration for calculating subspaces in slice 12: 15ms\n",
      "Slice number: 13, size of collision map: 9\n",
      "Duration for calculating subspaces in slice 13: 0ms\n",
      "Slice number: 14, size of collision map: 6\n",
      "Duration for calculating subspaces in slice 14: 0ms\n",
      "Slice number: 15, size of collision map: 5\n",
      "Duration for calculating subspaces in slice 15: 0ms\n",
      "Duration for the whole SubScale algorithm: 78ms\n",
      "Duration for the whole process: 132ms\n"
     ]
    }
   ],
   "source": [
    "dirpath = Path('out')\n",
    "if dirpath.exists() and dirpath.is_dir():\n",
    "    shutil.rmtree(dirpath)\n",
    "\n",
    "SAMPLEFILE = '6'\n",
    "GERMAN_FILE_FORMATTING = 'true'\n",
    "EPSILON = '0.5'\n",
    "MINPTS = '4'\n",
    "SPLITTING_SIZE = '16'\n",
    "EVENLY_SIZED_SLICES = 'true'\n",
    "DBSCAN = 'false'\n",
    "p = subprocess.Popen(['java',\n",
    "                      '-jar',\n",
    "                      'SubScaleExtended.jar',\n",
    "                      SAMPLEFILE,\n",
    "                      GERMAN_FILE_FORMATTING,\n",
    "                      EPSILON,\n",
    "                      MINPTS,\n",
    "                      SPLITTING_SIZE,\n",
    "                      EVENLY_SIZED_SLICES,\n",
    "                      DBSCAN],\n",
    "                     stdout=subprocess.PIPE,\n",
    "                     stderr=subprocess.STDOUT)\n",
    "for line in p.stdout:\n",
    "    print(str(line, \"utf-8\").replace('\\r\\n', ''))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-29.93002545,  22.56522383,  61.69234081, ..., -43.29171744,\n        -10.21352848,  42.79073344],\n       [-29.93068444,  22.56529513,  61.69310692, ...,  77.10241646,\n        -69.79696597,  48.81951259],\n       [-29.93005704,  22.56530251,  61.6933578 , ...,   7.81001096,\n         -6.44370418, -86.12515931],\n       ...,\n       [-96.38482979,  44.49869041,   7.50145534, ..., -99.19835352,\n        -46.45175958,  98.21611606],\n       [-87.19415821,  45.08820912,  27.55515226, ..., -80.66122312,\n         89.98719628,  25.92143484],\n       [ 67.84659032, -46.12026085,  15.20744954, ...,  39.30186145,\n        -83.41124807,  31.83975919]])"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "# Potential subspaces will be searched for clusters using the dbscan algorithm\n",
    "\n",
    "with open(\"out/results/found_clusters.csv\", mode=\"w\") as output_file:\n",
    "    with os.scandir(\"out/results/subspaces\") as it:\n",
    "        for entry in it:\n",
    "            if os.path.getsize(entry.path) > 0: # Check for empty file sometimes generated due to bug in SubScaleExtended.jar\n",
    "                df = pd.read_csv(entry.path, header=None, delimiter=\"-\")\n",
    "                for _, row in df.iterrows():\n",
    "                    points_indexes = json.loads(row[1])\n",
    "                    dimensions = json.loads(row[0])\n",
    "                    S = DB[points_indexes][:,dimensions]\n",
    "                    clustering = sklearn.cluster.DBSCAN(eps=0.004).fit(S)\n",
    "\n",
    "                    # Converting dbscan result in clusters.csv file-format\n",
    "                    unique_labels = set(clustering.labels_)\n",
    "                    unique_labels.discard(-1) # -1 stands for noisy samples and is therefore removed\n",
    "                    for k in unique_labels:\n",
    "                        U = np.array(points_indexes)[clustering.labels_ == k]\n",
    "                        output_file.write(str(dimensions) + \"-\" + str(U.tolist()) + \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "# f1-measure\n",
    "with open(\"out/results/found_clusters.csv\", mode=\"r\") as found_clusters_file, \\\n",
    "     open(\"res/ground_truth.csv\", mode=\"r\") as ground_truth_file:\n",
    "\n",
    "    found_clusters_df = pd.read_csv(found_clusters_file, header=None, delimiter=\"-\")\n",
    "    ground_truth_df = pd.read_csv(ground_truth_file, header=None, delimiter=\"-\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://www.ipd.kit.edu/~muellere/publications/BTW2011.pdf Erkl√§rung zu f1 measure\n",
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}